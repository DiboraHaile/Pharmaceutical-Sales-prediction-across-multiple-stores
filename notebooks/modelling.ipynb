{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import pandas as pd\n",
    "import sys  \n",
    "sys.path.insert(0, '../scripts')\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import clean_data\n",
    "import loading_data\n",
    "import utilities\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# load data\n",
    "df_store = loading_data.load_csv('../data/store.csv')\n",
    "df_train = loading_data.load_csv('../data/train.csv')\n",
    "df_test = loading_data.load_csv('../data/test.csv')\n",
    "df_submission = loading_data.load_csv('../data/sample_submission.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/dibora/Pharmaceutical-Sales-prediction-across-multiple-stores/pharmaceutical/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  \n",
      "/home/dibora/Pharmaceutical-Sales-prediction-across-multiple-stores/pharmaceutical/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/dibora/Pharmaceutical-Sales-prediction-across-multiple-stores/pharmaceutical/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  after removing the cwd from sys.path.\n",
      "/home/dibora/Pharmaceutical-Sales-prediction-across-multiple-stores/pharmaceutical/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# display some data from training and testing data\n",
    "### The testing data contains 8 columns, it doesn't include the sales because that is what we will be predicting.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_test.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday',\n",
       "       'SchoolHoliday'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Step\n",
    "### Process the data into a format where it can be fed to a machine learning model. This typically means converting all non-numeric columns to numeric, handling NaN values and generating new features from already existing features. \n",
    "\n",
    "### In our case, you have a few datetime columns to preprocess. you can extract the following from them:\n",
    "- weekdays\n",
    "- weekends \n",
    "- number of days to holidays\n",
    "- Number of days after holiday\n",
    "- Beginning of month, mid month and ending of month\n",
    "(think of more features to extract), extra marks for it\n",
    "\t\t\t\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We will define functions to do preprocessing on data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# class to include custom functions on dataframes\n",
    "# in the pipeline\n",
    "class df_function_transformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def handle_outliers(df):\n",
    "    sales_dec = df.quantile(0.10)\n",
    "    sales_qua = df.quantile(0.90)\n",
    "    df = np.where(df < sales_dec, sales_dec,df)\n",
    "    df = np.where(df >sales_qua, sales_qua,df)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# function to create more features from Date columns\n",
    "def get_features(df_train): \n",
    "    # extracting numerical information from the date columns\n",
    "    # the year\n",
    "    df_train_copy = df_train.copy()\n",
    "    df_train_copy[\"Year\"] = df_train_copy['Date'].dt.year\n",
    "    # which part of the month it is where 0 is begining, 1 is mid and 2 is end\n",
    "    df_train_copy[\"Part of the month\"] = df_train_copy['Date'].dt.day.apply(lambda x: x // 10)\n",
    "    df_train_copy.loc[(df_train_copy[\"Date\"].dt.day == 31), \"Part of the month\"] = 2\n",
    "    df_train_copy = df_train_copy.drop(columns=\"Date\")\n",
    "    # How many days before or after holidays\n",
    "    return df_train_copy\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# function to convert to dataframe\n",
    "def format_datetime(df):\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def prepare_model_input(df):\n",
    "    df_y = df[\"Sales\"]\n",
    "    df_X = df.drop(columns=[\"Sales\"])\n",
    "    return df_X, df_y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We will use sklearn pipeline to preprocess, scale and prepare features from out dataset.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# preprocess data\n",
    "def preprocess(df):\n",
    "    categorical_preprocessing = Pipeline([('ohe', OneHotEncoder())])\n",
    "    numerical_preprocessing = Pipeline([('imputation', SimpleImputer())])\n",
    "\n",
    "    # define which transformer applies to which columns\n",
    "    preprocess = ColumnTransformer([\n",
    "        ('categorical_preprocessing', categorical_preprocessing, ['StateHoliday']),\n",
    "        ('numerical_preprocessing', numerical_preprocessing, ['Store', 'DayOfWeek','Customers', 'Open', 'Promo'\n",
    "            ,'SchoolHoliday'])\n",
    "    ])\n",
    "    training_pipeline = Pipeline([\n",
    "        (\"convert_Date_format\", df_function_transformer(format_datetime)),\n",
    "        (\"get features from Date\",df_function_transformer(get_features)),\n",
    "        (\"encode and impute\", preprocess),\n",
    "        (\"Scale\",StandardScaler())\n",
    "        \n",
    "    ])\n",
    "    return training_pipeline.fit_transform(df)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def train_model(X,y,model):\n",
    "    reg = model.fit(X, y)\n",
    "    return reg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def inference_model(X,model):\n",
    "    return model.predict(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# get features and target\n",
    "df_features,df_target = prepare_model_input(df_train)\n",
    "y = np.array(handle_outliers(df_target))\n",
    "X = preprocess(df_features)\n",
    "\n",
    "# split into valid and training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.3, random_state=12)\n",
    "# train with training data\n",
    "reg = LinearRegression()\n",
    "trained_model = train_model(X_train,y_train,reg)\n",
    "score = trained_model.score(X_valid, y_valid)\n",
    "print(\"The score of the trained Linear regression model is \",score)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The score of the trained Linear regression model is  0.8323756220121866\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### When we take out the customers column and train our model, accuracy significantly reduces\n",
    "#### MSE is almost always positive is because of randomness or because the estimator does not calculate a negative value as it is squared. The MSE values closer to zero are better as this refers that model has less error. the advantage of MSE is, it doesn't handle outliers well. MAE is another loss function which calculates absolute error, so we will use MAE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Go back to the exploratory notebook and check out the distribution between test and train data\n",
    "# to understand how the outputs should be\n",
    "y_pred_valid = inference_model(X_valid,trained_model)\n",
    "# mse = mean_squared_error(y_valid, y_pred_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred_valid)\n",
    "print(\"The mean absolute error of our model is \",mae)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The mean absolute error of our model is  963.9218931840745\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pharmaceutical': venv)"
  },
  "interpreter": {
   "hash": "3111f4c5a366be439e2804dc4d42d279c7960b52b896a3ee11ceabeb285b6b48"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}